<h1>
  <span class="prefix"></span>
  <span class="headline">NLP and LLMs - Foundations of NLP</span>
</h1>

## About
NLP foundations introduces various ways to represent text numerically including word vectors and text embeddings. 

## Learning Objectives

*You will be able to:*

- Define common use cases for text data.
- Describe the evolution of text representation from traditional methods to embeddings.
- Apply CountVectorizer, TF-IDF to complete a sentiment analysis of customer reviews.
- Compare two embedding methods, Word2Vec and BERT, using customer reviews.
- Discuss real-world considerations for embedding selection.

## Content

| Topic |  About |
| ------ | ------ |
| [Full Lesson Deck](https://git.generalassemb.ly/modular-curriculum-all-courses/dsb-nlp-template/tree/master/01-slides) | To be used for the full session, includes the labs below  |
|  [text-frequency.ipynb](https://git.generalassemb.ly/modular-curriculum-all-courses/dsb-nlp-template/tree/master/02-text-frequency) | First code-a-long and mini-lab  |
|  [embeddings.ipynb](https://git.generalassemb.ly/modular-curriculum-all-courses/dsb-nlp-template/tree/master/03-embeddings) | Second code-a-long |



## Prerequisites
- Write and run Python code in a Jupyter notebook.
- Create basic Python functions.
- Import and use `pandas` and `numpy`.
- Understand, run, and evaluate classification models and metrics in scikit-learn.

## References

ðŸ“– [Reference Materials](./references/README.md)


## [Instructor-only resources](https://drive.google.com/drive/folders/11RRHpnnKbtMHJp6X21gSzyUslBdvQVZM?usp=drive_link)





